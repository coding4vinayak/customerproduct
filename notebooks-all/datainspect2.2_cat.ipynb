{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   case_id  Hospital_code Hospital_type_code  City_Code_Hospital  \\\n",
      "0        1              8                  c             3.00000   \n",
      "1        2              2                  c             5.00000   \n",
      "2        3             10                  e             1.00000   \n",
      "3        4             26                  b             4.69814   \n",
      "4        5             26                  b             2.00000   \n",
      "\n",
      "  Hospital_region_code  Available Extra Rooms in Hospital    Department  \\\n",
      "0                    Z                                3.0  radiotherapy   \n",
      "1                    Z                                2.0  radiotherapy   \n",
      "2                    X                                2.0    anesthesia   \n",
      "3                    Y                                2.0  radiotherapy   \n",
      "4                    Y                                2.0  radiotherapy   \n",
      "\n",
      "  Ward_Type Ward_Facility_Code Bed Grade  patientid  City_Code_Patient  \\\n",
      "0         R                  F       2.0      31397                7.0   \n",
      "1         S                  F       2.0      31397                7.0   \n",
      "2         S                  E       2.0      31397                7.0   \n",
      "3         R                  D       2.0      31397                7.0   \n",
      "4         S                  D       2.0      31397                7.0   \n",
      "\n",
      "  Type of Admission Severity of Illness  Visitors with Patient   Age  \\\n",
      "0         Emergency             Extreme                    2.0  55.5   \n",
      "1            Trauma             Extreme                    2.0  55.5   \n",
      "2            Trauma             Extreme                    2.0  55.5   \n",
      "3            Trauma             Extreme                    2.0  55.5   \n",
      "4            Trauma             Extreme                    2.0  55.5   \n",
      "\n",
      "   Admission_Deposit  Stay  \n",
      "0             4911.0   5.0  \n",
      "1             5954.0  45.5  \n",
      "2             4745.0  35.5  \n",
      "3             7272.0  45.5  \n",
      "4             5558.0  45.5  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# Load data from CSV file (replace with your actual CSV file path)\n",
    "data = pd.read_csv('/teamspace/studios/this_studio/data/csv-clean/synthetic000-cleaned.csv')\n",
    "\n",
    "# Load classifications from JSON file (replace with your actual JSON file path)\n",
    "classifications_file_path = '/teamspace/studios/this_studio/csvandmetadata export /json/classifications_0000.json'\n",
    "with open(classifications_file_path, 'r') as f:\n",
    "    classifications = json.load(f)\n",
    "\n",
    "# Define a function to apply operations based on classifications\n",
    "def apply_operations_based_on_classification(data, classifications):\n",
    "    # Convert classifications to lowercase keys for easier matching\n",
    "    classifications_lower = {k.lower(): v for k, v in classifications.items()}\n",
    "    \n",
    "    # Identify numeric columns\n",
    "    numeric_columns = data.select_dtypes(include='number')\n",
    "    \n",
    "    # Calculate min-max range for numeric columns\n",
    "    min_max_range = numeric_columns.max() - numeric_columns.min()\n",
    "    \n",
    "    # Initialize scalers\n",
    "    scaler_standard = StandardScaler()\n",
    "    scaler_minmax = MinMaxScaler()\n",
    "\n",
    "\n",
    "\n",
    "    # Process each column in the DataFrame\n",
    "    for col in data.columns:\n",
    "        col_lower = col.lower()  # Convert column name to lowercase for matching\n",
    "        \n",
    "        if col_lower in classifications_lower:\n",
    "            classification = classifications_lower[col_lower]\n",
    "            \n",
    "            if classification == 'numeric data':\n",
    "                if min_max_range.mean() < 10:\n",
    "                    # Use MinMaxScaler for normalization if range is small\n",
    "                    data[col] = scaler_minmax.fit_transform(data[[col]])\n",
    "                elif numeric_columns[col].abs().skew() > 0.5:\n",
    "                    # Use StandardScaler for standardization if data is skewed\n",
    "                    data[col] = scaler_standard.fit_transform(data[[col]])\n",
    "                else:\n",
    "                    # Default to StandardScaler if no specific conditions are met\n",
    "                    data[col] = scaler_standard.fit_transform(data[[col]])\n",
    "            \n",
    "            # Add conditions for other classifications if needed\n",
    "            elif classification == 'categorical data':\n",
    "                # Handle categorical data (if needed)\n",
    "                pass\n",
    "            elif classification == 'temporal data':\n",
    "                # Handle temporal data (if needed)\n",
    "                pass\n",
    "\n",
    "    return data\n",
    "\n",
    "# Apply operations based on classifications\n",
    "data_processed = apply_operations_based_on_classification(data, classifications)\n",
    "\n",
    "# Example: Print first few rows of processed data\n",
    "print(data_processed.head())\n",
    "\n",
    "# Example: Save the processed data back to CSV\n",
    "data_processed.to_csv('processed_combined_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "categerial what can we do immidiate is \n",
    "1. is sring numeric values are cast as numeric values like age and stay\n",
    "2. if nunique are less tha n5 or equal to five one hot\n",
    "3. lable encoding whole dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non-Ordinal Data for Non-Tree-Based Models:\n",
    "\n",
    "For algorithms like linear regression, logistic regression, k-nearest neighbors (KNN), support vector machines (SVM), and neural networks, label encoding can cause problems if the data is not ordinal. These algorithms can interpret the encoded values as having an inherent order or relationship, which might not be accurate.\n",
    "\n",
    "so below code for non ordinal opration "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in earlier combile floate and inter in numeric daata "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   case_id  Hospital_code Hospital_type_code  City_Code_Hospital  \\\n",
      "0        1              8                  c             3.00000   \n",
      "1        2              2                  c             5.00000   \n",
      "2        3             10                  e             1.00000   \n",
      "3        4             26                  b             4.69814   \n",
      "4        5             26                  b             2.00000   \n",
      "\n",
      "  Hospital_region_code  Available Extra Rooms in Hospital    Department  \\\n",
      "0                    Z                                3.0  radiotherapy   \n",
      "1                    Z                                2.0  radiotherapy   \n",
      "2                    X                                2.0    anesthesia   \n",
      "3                    Y                                2.0  radiotherapy   \n",
      "4                    Y                                2.0  radiotherapy   \n",
      "\n",
      "  Ward_Type Ward_Facility_Code Bed Grade  patientid  City_Code_Patient  \\\n",
      "0         R                  F       2.0      31397                7.0   \n",
      "1         S                  F       2.0      31397                7.0   \n",
      "2         S                  E       2.0      31397                7.0   \n",
      "3         R                  D       2.0      31397                7.0   \n",
      "4         S                  D       2.0      31397                7.0   \n",
      "\n",
      "  Type of Admission Severity of Illness  Visitors with Patient   Age  \\\n",
      "0         Emergency             Extreme                    2.0  55.5   \n",
      "1            Trauma             Extreme                    2.0  55.5   \n",
      "2            Trauma             Extreme                    2.0  55.5   \n",
      "3            Trauma             Extreme                    2.0  55.5   \n",
      "4            Trauma             Extreme                    2.0  55.5   \n",
      "\n",
      "   Admission_Deposit  Stay  \n",
      "0             4911.0   5.0  \n",
      "1             5954.0  45.5  \n",
      "2             4745.0  35.5  \n",
      "3             7272.0  45.5  \n",
      "4             5558.0  45.5  \n"
     ]
    }
   ],
   "source": [
    "# script for non ordinal data   \n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder  \n",
    "\n",
    "# Load data from CSV file (replace with your actual CSV file path)\n",
    "data = pd.read_csv('/teamspace/studios/this_studio/data/csv-clean/synthetic000-cleaned.csv')\n",
    "\n",
    "# Load classifications from JSON file (replace with your actual JSON file path)\n",
    "classifications_file_path = '/teamspace/studios/this_studio/csvandmetadata export /json/classifications_0000.json'\n",
    "with open(classifications_file_path, 'r') as f:\n",
    "    classifications = json.load(f)\n",
    "\n",
    "# Define a function to apply operations based on classifications\n",
    "def apply_operations_based_on_classification(data, classifications):\n",
    "    # Convert classifications to lowercase keys for easier matching\n",
    "    classifications_lower = {k.lower(): v for k, v in classifications.items()}\n",
    "    \n",
    "    # Identify numeric columns\n",
    "    numeric_columns = data.select_dtypes(include='number')\n",
    "    \n",
    "    # Calculate min-max range for numeric columns\n",
    "    min_max_range = numeric_columns.max() - numeric_columns.min()\n",
    "    \n",
    "    # Initialize scalers\n",
    "    scaler_standard = StandardScaler()\n",
    "    scaler_minmax = MinMaxScaler()\n",
    "    le = LabelEncoder()\n",
    "\n",
    "\n",
    "    # Process each column in the DataFrame\n",
    "    for col in data.columns:\n",
    "        col_lower = col.lower()  # Convert column name to lowercase for matching\n",
    "        \n",
    "        if col_lower in classifications_lower:\n",
    "            classification = classifications_lower[col_lower]\n",
    "            \n",
    "            if classification == 'numeric data':\n",
    "                if min_max_range.mean() < 10:\n",
    "                    # Use MinMaxScaler for normalization if range is small\n",
    "                    data[col] = scaler_minmax.fit_transform(data[[col]])\n",
    "                elif numeric_columns[col].abs().skew() > 0.5:\n",
    "                    # Use StandardScaler for standardization if data is skewed\n",
    "                    data[col] = scaler_standard.fit_transform(data[[col]])\n",
    "                else:\n",
    "                    # Default to StandardScaler if no specific conditions are met\n",
    "                    data[col] = scaler_standard.fit_transform(data[[col]])\n",
    "            \n",
    "            # Add conditions for other classifications if needed\n",
    "            elif classification == 'categorical data':\n",
    "                if  data[col].nunique() < 10:\n",
    "                    data = pd.get_dummies(data, columns=[col])\n",
    "                elif data[col].nunique() > 10:\n",
    "                    data[col] = data[col].astype('category').cat.codes\n",
    "                \n",
    "            \n",
    "            elif classification == 'email data':\n",
    "                if data[col].str.contains('@').any():  # Ensure it's email data\n",
    "                    data[col] = data[col].apply(hash_email)\n",
    "                \n",
    "            elif classification == 'temporal data': #TIME OF DATES\n",
    "                data[col] = pd.to_datetime(data[col])\n",
    "                data[col + '_year'] = data[col].dt.year\n",
    "                data[col + '_month'] = data[col].dt.month\n",
    "                data[col + '_day'] = data[col].dt.day\n",
    "                data[col + '_hour'] = data[col].dt.hour\n",
    "                data[col + '_minute'] = data[col].dt.minute\n",
    "                data[col + '_second'] = data[col].dt.second\n",
    "                data = data.drop(columns=[col])\n",
    "                \n",
    "            elif classfication ==  'ID Data':\n",
    "                if data[col].nunique() == data.shape[0]:\n",
    "                   data = data.drop(columns=[col])\n",
    "                elif pd.api.types.is_numeric_dtype(data[col]):\n",
    "                   data[[col]] = scaler_minmax.fit_transform(data[[col]])\n",
    "                elif data[col].dtype == 'object':\n",
    "                   data[col] = data[col].astype('category').cat.codes\n",
    "\n",
    "            elif classification == 'location data':\n",
    "                data[col] = data[col].astype('category').cat.codes\n",
    "\n",
    "            elif classification == 'phone number data':\n",
    "                data[col] = data[col].astype('category').cat.codes\n",
    "\n",
    "            elif classsification == 'binary data':\n",
    "                if data[col].nunique() == 2:\n",
    "                   data[col] = le.fit_transform(data[col])\n",
    "\n",
    "            \n",
    "                \n",
    "\n",
    "    return data\n",
    "\n",
    "# Apply operations based on classifications\n",
    "data_processed = apply_operations_based_on_classification(data, classifications)\n",
    "\n",
    "# Example: Print first few rows of processed data\n",
    "print(data_processed.head())\n",
    "\n",
    "# Example: Save the processed data back to CSV\n",
    "data_processed.to_csv('processed_combined_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For algorithms like decision trees, random forests, and gradient boosting, label encoding can be effective even if the data is not ordinal because these models are not sensitive to the numerical ordering of labels. These models can handle categorical features encoded as integers.\n",
    "\n",
    "we will use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   case_id  Hospital_code Hospital_type_code  City_Code_Hospital  \\\n",
      "0        1              8                  c             3.00000   \n",
      "1        2              2                  c             5.00000   \n",
      "2        3             10                  e             1.00000   \n",
      "3        4             26                  b             4.69814   \n",
      "4        5             26                  b             2.00000   \n",
      "\n",
      "  Hospital_region_code  Available Extra Rooms in Hospital    Department  \\\n",
      "0                    Z                                3.0  radiotherapy   \n",
      "1                    Z                                2.0  radiotherapy   \n",
      "2                    X                                2.0    anesthesia   \n",
      "3                    Y                                2.0  radiotherapy   \n",
      "4                    Y                                2.0  radiotherapy   \n",
      "\n",
      "  Ward_Type Ward_Facility_Code Bed Grade  patientid  City_Code_Patient  \\\n",
      "0         R                  F       2.0      31397                7.0   \n",
      "1         S                  F       2.0      31397                7.0   \n",
      "2         S                  E       2.0      31397                7.0   \n",
      "3         R                  D       2.0      31397                7.0   \n",
      "4         S                  D       2.0      31397                7.0   \n",
      "\n",
      "  Type of Admission Severity of Illness  Visitors with Patient   Age  \\\n",
      "0         Emergency             Extreme                    2.0  55.5   \n",
      "1            Trauma             Extreme                    2.0  55.5   \n",
      "2            Trauma             Extreme                    2.0  55.5   \n",
      "3            Trauma             Extreme                    2.0  55.5   \n",
      "4            Trauma             Extreme                    2.0  55.5   \n",
      "\n",
      "   Admission_Deposit  Stay  \n",
      "0             4911.0   5.0  \n",
      "1             5954.0  45.5  \n",
      "2             4745.0  35.5  \n",
      "3             7272.0  45.5  \n",
      "4             5558.0  45.5  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load data from CSV file (replace with your actual CSV file path)\n",
    "data = pd.read_csv('/teamspace/studios/this_studio/data/csv-clean/synthetic565-cleaned.csv')\n",
    "\n",
    "# Load classifications from JSON file (replace with your actual JSON file path)\n",
    "classifications_file_path = '/teamspace/studios/this_studio/csvandmetadata export /json/claasification_555.json'\n",
    "with open(classifications_file_path, 'r') as f:\n",
    "    classifications = json.load(f)\n",
    "\n",
    "# Define a function to apply operations based on classifications\n",
    "def apply_operations_based_on_classification(data, classifications):\n",
    "    # Convert classifications to lowercase keys for easier matching\n",
    "    classifications_lower = {k.lower(): v for k, v in classifications.items()}\n",
    "    \n",
    "    # Identify numeric columns\n",
    "    numeric_columns = data.select_dtypes(include='number')\n",
    "    \n",
    "    # Calculate min-max range for numeric columns\n",
    "    min_max_range = numeric_columns.max() - numeric_columns.min()\n",
    "    \n",
    "    # Initialize scalers\n",
    "    scaler_standard = StandardScaler()\n",
    "    scaler_minmax = MinMaxScaler()\n",
    "\n",
    "    # Compute skewness for numeric columns\n",
    "    skewness = numeric_columns.skew()\n",
    "\n",
    "    # Process each column in the DataFrame\n",
    "    for col in data.columns:\n",
    "        col_lower = col.lower()  # Convert column name to lowercase for matching\n",
    "        \n",
    "        if col_lower in classifications_lower:\n",
    "            classification = classifications_lower[col_lower]\n",
    "            \n",
    "            if classification == 'numeric data':\n",
    "                if min_max_range[col] < 10:\n",
    "                    # Use MinMaxScaler for normalization if range is small\n",
    "                    data[col] = scaler_minmax.fit_transform(data[[col]])\n",
    "                elif skewness[col] > 0.5:\n",
    "                    # Use StandardScaler for standardization if data is skewed\n",
    "                    data[col] = scaler_standard.fit_transform(data[[col]])\n",
    "                else:\n",
    "                    # Default to StandardScaler if no specific conditions are met\n",
    "                    data[col] = scaler_standard.fit_transform(data[[col]])\n",
    "            \n",
    "            # Add conditions for other classifications if needed\n",
    "            elif classification == 'categorical data':\n",
    "                if data[col].nunique() < 10:\n",
    "                    data = pd.get_dummies(data, columns=[col])\n",
    "                else:\n",
    "                    le = LabelEncoder()\n",
    "                    data[col] = le.fit_transform(data[col])\n",
    "            \n",
    "            # Handle additional classifications if needed\n",
    "            # elif classification == 'temporal data':\n",
    "            #     # Handle temporal data (if needed)\n",
    "            #     pass\n",
    "\n",
    "    return data\n",
    "\n",
    "# Apply operations based on classifications\n",
    "data_processed = apply_operations_based_on_classification(data, classifications)\n",
    "\n",
    "# Example: Print first few rows of processed data\n",
    "print(data_processed.head())\n",
    "\n",
    "# Example: Save the processed data back to CSV\n",
    "data_processed.to_csv('processed_combined_data_final_2.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    case_id  Hospital_code  City_Code_Hospital  \\\n",
      "0 -1.735116      -1.244013           -0.524763   \n",
      "1 -1.734423      -1.932504            0.093487   \n",
      "2 -1.733729      -1.014516           -1.143013   \n",
      "3 -1.733036       0.821461            0.000174   \n",
      "4 -1.732343       0.821461           -0.833888   \n",
      "\n",
      "   Available Extra Rooms in Hospital  patientid  City_Code_Patient  \\\n",
      "0                           0.222222  -0.965397           0.029048   \n",
      "1                           0.111111  -0.965397           0.029048   \n",
      "2                           0.111111  -0.965397           0.029048   \n",
      "3                           0.111111  -0.965397           0.029048   \n",
      "4                           0.111111  -0.965397           0.029048   \n",
      "\n",
      "   Visitors with Patient       Age  Admission_Deposit  Stay  ...  \\\n",
      "0              -0.736972  0.246822           0.016381     4  ...   \n",
      "1              -0.736972  0.246822           1.034451     3  ...   \n",
      "2              -0.736972  0.246822          -0.145651     2  ...   \n",
      "3              -0.736972  0.246822           2.320946     3  ...   \n",
      "4              -0.736972  0.246822           0.647916     3  ...   \n",
      "\n",
      "   Ward_Facility_Code_F  Bed Grade_2.0  Bed Grade_3.0  Bed Grade_4.0  \\\n",
      "0                  True           True          False          False   \n",
      "1                  True           True          False          False   \n",
      "2                 False           True          False          False   \n",
      "3                 False           True          False          False   \n",
      "4                 False           True          False          False   \n",
      "\n",
      "   Bed Grade_nan.0  Bed Grade_nana.0  Type of Admission_Trauma  \\\n",
      "0            False             False                     False   \n",
      "1            False             False                      True   \n",
      "2            False             False                      True   \n",
      "3            False             False                      True   \n",
      "4            False             False                      True   \n",
      "\n",
      "   Type of Admission_Urgent  Severity of Illness_Minor  \\\n",
      "0                     False                      False   \n",
      "1                     False                      False   \n",
      "2                     False                      False   \n",
      "3                     False                      False   \n",
      "4                     False                      False   \n",
      "\n",
      "   Severity of Illness_Moderate  \n",
      "0                         False  \n",
      "1                         False  \n",
      "2                         False  \n",
      "3                         False  \n",
      "4                         False  \n",
      "\n",
      "[5 rows x 41 columns]\n"
     ]
    }
   ],
   "source": [
    "#fix categorical data\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load data from CSV file\n",
    "data = pd.read_csv('/teamspace/studios/this_studio/data/csv-clean/synthetic565-cleaned.csv')\n",
    "\n",
    "# Load classifications from JSON file\n",
    "classifications_file_path = '/teamspace/studios/this_studio/csvandmetadata export /json/claasification_555.json'\n",
    "with open(classifications_file_path, 'r') as f:\n",
    "    classifications = json.load(f)\n",
    "\n",
    "# Define a function to apply operations based on classifications\n",
    "def apply_operations_based_on_classification(data, classifications):\n",
    "    # Initialize scalers\n",
    "    scaler_standard = StandardScaler()\n",
    "    scaler_minmax = MinMaxScaler()\n",
    "\n",
    "    # Process each column in the DataFrame\n",
    "    for col in data.columns:\n",
    "        col_lower = col.lower()  # Convert column name to lowercase for matching\n",
    "\n",
    "        # Find the classification for the column\n",
    "        classification = None\n",
    "        for key, value in classifications.items():\n",
    "            if col in value:\n",
    "                classification = key\n",
    "                break\n",
    "\n",
    "        if classification is None:\n",
    "            continue  # Skip if no classification is found\n",
    "\n",
    "        if classification == 'Numeric Data':\n",
    "            # Calculate min-max range and skewness for the column\n",
    "            min_max_range = data[col].max() - data[col].min()\n",
    "            skewness = data[col].skew()\n",
    "\n",
    "            if min_max_range < 10:\n",
    "                # Use MinMaxScaler for normalization if range is small\n",
    "                data[col] = scaler_minmax.fit_transform(data[[col]])\n",
    "            elif skewness > 0.5:\n",
    "                # Use StandardScaler for standardization if data is skewed\n",
    "                data[col] = scaler_standard.fit_transform(data[[col]])\n",
    "            else:\n",
    "                # Default to StandardScaler if no specific conditions are met\n",
    "                data[col] = scaler_standard.fit_transform(data[[col]])\n",
    "\n",
    "        elif classification == 'Categorical Data':\n",
    "            if data[col].nunique() < 10:\n",
    "                # Use one-hot encoding if unique values are less than 10\n",
    "                data = pd.get_dummies(data, columns=[col], drop_first=True)\n",
    "            else:\n",
    "                # Use label encoding if unique values are 10 or more\n",
    "                le = LabelEncoder()\n",
    "                data[col] = le.fit_transform(data[col])\n",
    "\n",
    "        # Add conditions for other classifications if needed\n",
    "        # elif classification == 'Temporal Data':\n",
    "        #     # Handle temporal data (if needed)\n",
    "        #     pass\n",
    "\n",
    "    return data\n",
    "\n",
    "# Apply operations based on classifications\n",
    "data_processed = apply_operations_based_on_classification(data, classifications)\n",
    "\n",
    "# Example: Print first few rows of processed data\n",
    "print(data_processed.head())\n",
    "\n",
    "# Example: Save the processed data back to CSV\n",
    "data_processed.to_csv('/teamspace/studios/this_studio/data/csv-clean/processed_combined_data_final_2.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    case_id  Hospital_code  City_Code_Hospital  \\\n",
      "0 -1.735116      -1.244013           -0.524763   \n",
      "1 -1.734423      -1.932504            0.093487   \n",
      "2 -1.733729      -1.014516           -1.143013   \n",
      "3 -1.733036       0.821461            0.000174   \n",
      "4 -1.732343       0.821461           -0.833888   \n",
      "\n",
      "   Available Extra Rooms in Hospital  patientid  City_Code_Patient  \\\n",
      "0                           0.222222  -0.965397           0.029048   \n",
      "1                           0.111111  -0.965397           0.029048   \n",
      "2                           0.111111  -0.965397           0.029048   \n",
      "3                           0.111111  -0.965397           0.029048   \n",
      "4                           0.111111  -0.965397           0.029048   \n",
      "\n",
      "   Visitors with Patient       Age  Admission_Deposit  Stay  ...  \\\n",
      "0              -0.736972  0.246822           0.016381     4  ...   \n",
      "1              -0.736972  0.246822           1.034451     3  ...   \n",
      "2              -0.736972  0.246822          -0.145651     2  ...   \n",
      "3              -0.736972  0.246822           2.320946     3  ...   \n",
      "4              -0.736972  0.246822           0.647916     3  ...   \n",
      "\n",
      "   Ward_Facility_Code_F  Bed Grade_2.0  Bed Grade_3.0  Bed Grade_4.0  \\\n",
      "0                     1              1              0              0   \n",
      "1                     1              1              0              0   \n",
      "2                     0              1              0              0   \n",
      "3                     0              1              0              0   \n",
      "4                     0              1              0              0   \n",
      "\n",
      "   Bed Grade_nan.0  Bed Grade_nana.0  Type of Admission_Trauma  \\\n",
      "0                0                 0                         0   \n",
      "1                0                 0                         1   \n",
      "2                0                 0                         1   \n",
      "3                0                 0                         1   \n",
      "4                0                 0                         1   \n",
      "\n",
      "   Type of Admission_Urgent  Severity of Illness_Minor  \\\n",
      "0                         0                          0   \n",
      "1                         0                          0   \n",
      "2                         0                          0   \n",
      "3                         0                          0   \n",
      "4                         0                          0   \n",
      "\n",
      "   Severity of Illness_Moderate  \n",
      "0                             0  \n",
      "1                             0  \n",
      "2                             0  \n",
      "3                             0  \n",
      "4                             0  \n",
      "\n",
      "[5 rows x 41 columns]\n"
     ]
    }
   ],
   "source": [
    "# really final script for all data types\n",
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import hashlib\n",
    "\n",
    "# Load data from CSV file\n",
    "data = pd.read_csv('/teamspace/studios/this_studio/data/csv-clean/synthetic565-cleaned.csv')\n",
    "\n",
    "# Load classifications from JSON file\n",
    "classifications_file_path = '/teamspace/studios/this_studio/csvandmetadata export /json/claasification_555.json'\n",
    "with open(classifications_file_path, 'r') as f:\n",
    "    classifications = json.load(f)\n",
    "\n",
    "# Define a function to apply operations based on classifications\n",
    "def apply_operations_based_on_classification(data, classifications):\n",
    "    # Initialize scalers\n",
    "    scaler_standard = StandardScaler()\n",
    "    scaler_minmax = MinMaxScaler()\n",
    "\n",
    "    # Process each column in the DataFrame\n",
    "    for col in data.columns:\n",
    "        col_lower = col.lower()  # Convert column name to lowercase for matching\n",
    "\n",
    "        # Find the classification for the column\n",
    "        classification = None\n",
    "        for key, value in classifications.items():\n",
    "            if col in value:\n",
    "                classification = key\n",
    "                break\n",
    "\n",
    "        if classification is None:\n",
    "            continue  # Skip if no classification is found\n",
    "\n",
    "        if classification == 'Numeric Data':\n",
    "            # Calculate min-max range and skewness for the column\n",
    "            min_max_range = data[col].max() - data[col].min()\n",
    "            skewness = data[col].skew()\n",
    "\n",
    "            if min_max_range < 10:\n",
    "                # Use MinMaxScaler for normalization if range is small\n",
    "                data[col] = scaler_minmax.fit_transform(data[[col]])\n",
    "            elif skewness > 0.5:\n",
    "                # Use StandardScaler for standardization if data is skewed\n",
    "                data[col] = scaler_standard.fit_transform(data[[col]])\n",
    "            else:\n",
    "                # Default to StandardScaler if no specific conditions are met\n",
    "                data[col] = scaler_standard.fit_transform(data[[col]])\n",
    "\n",
    "        elif classification == 'Categorical Data':\n",
    "            if data[col].nunique() < 10:\n",
    "                # Use one-hot encoding if unique values are less than 10\n",
    "                data = pd.get_dummies(data, columns=[col], drop_first=True)\n",
    "            else:\n",
    "                # Use label encoding if unique values are 10 or more\n",
    "                le = LabelEncoder()\n",
    "                data[col] = le.fit_transform(data[col])\n",
    "\n",
    "\n",
    "        \n",
    "            \n",
    "        #elif classification == 'Email Data':\n",
    "            #email opration to be happen here\n",
    "            #data[col] = data[col].apply(hash_email)\n",
    "                \n",
    "        # Convert boolean columns to 0 and 1\n",
    "        bool_columns = data.select_dtypes(include='bool').columns\n",
    "        data[bool_columns] = data[bool_columns].astype(int)\n",
    "\n",
    "        # Add conditions for other classifications if needed\n",
    "        # elif classification == 'Temporal Data':\n",
    "        #     # Handle temporal data (if needed)\n",
    "        #     pass\n",
    "\n",
    "    return data\n",
    "\n",
    "# Apply operations based on classifications\n",
    "data_processed = apply_operations_based_on_classification(data, classifications)\n",
    "\n",
    "# Example: Print first few rows of processed data\n",
    "print(data_processed.head())\n",
    "\n",
    "# Example: Save the processed data back to CSV\n",
    "data_processed.to_csv('/teamspace/studios/this_studio/data/csv-clean/processed_combined_data_final_3.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "# for tempora and binary \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
