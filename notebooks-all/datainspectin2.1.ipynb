{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pre processing stage to do ask user target and put that aat last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4994 entries, 0 to 4993\n",
      "Data columns (total 18 columns):\n",
      " #   Column                             Non-Null Count  Dtype  \n",
      "---  ------                             --------------  -----  \n",
      " 0   case_id                            4994 non-null   int64  \n",
      " 1   Hospital_code                      4994 non-null   int64  \n",
      " 2   Hospital_type_code                 4994 non-null   object \n",
      " 3   City_Code_Hospital                 4994 non-null   float64\n",
      " 4   Hospital_region_code               4994 non-null   object \n",
      " 5   Available Extra Rooms in Hospital  4994 non-null   float64\n",
      " 6   Department                         4994 non-null   object \n",
      " 7   Ward_Type                          4994 non-null   object \n",
      " 8   Ward_Facility_Code                 4994 non-null   object \n",
      " 9   Bed Grade                          4994 non-null   object \n",
      " 10  patientid                          4994 non-null   int64  \n",
      " 11  City_Code_Patient                  4994 non-null   float64\n",
      " 12  Type of Admission                  4994 non-null   object \n",
      " 13  Severity of Illness                4994 non-null   object \n",
      " 14  Visitors with Patient              4994 non-null   float64\n",
      " 15  Age                                4994 non-null   float64\n",
      " 16  Admission_Deposit                  4994 non-null   float64\n",
      " 17  Stay                               4994 non-null   object \n",
      "dtypes: float64(6), int64(3), object(9)\n",
      "memory usage: 702.4+ KB\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('/teamspace/studios/this_studio/data/csv-clean/synthetic000-cleaned.csv')\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integer Data: ['case_id', 'Hospital_code', 'patientid']\n",
      "Float Data: ['City_Code_Hospital', 'Available Extra Rooms in Hospital', 'City_Code_Patient', 'Visitors with Patient', 'Age', 'Admission_Deposit']\n",
      "Numeric Data: ['case_id', 'Hospital_code', 'City_Code_Hospital', 'Available Extra Rooms in Hospital', 'patientid', 'City_Code_Patient', 'Visitors with Patient', 'Age', 'Admission_Deposit']\n",
      "Categorical Data: ['Hospital_type_code', 'Hospital_region_code', 'Department', 'Ward_Type', 'Ward_Facility_Code', 'Bed Grade', 'Type of Admission', 'Severity of Illness', 'Stay']\n",
      "Binary Data: []\n",
      "Email Data: []\n",
      "Temporal Data: []\n",
      "id data: []\n",
      "Numeric columns: ['case_id', 'Hospital_code', 'City_Code_Hospital', 'Available Extra Rooms in Hospital', 'patientid', 'City_Code_Patient', 'Visitors with Patient', 'Age', 'Admission_Deposit']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "class ClassifiedDataFrame(pd.DataFrame):\n",
    "    _metadata = ['classifications']\n",
    "\n",
    "    def classify_columns(self):\n",
    "        classifications = {\n",
    "            'Integer Data': [],\n",
    "            'Float Data': [],\n",
    "            'Numeric Data': [],\n",
    "            'Categorical Data': [],\n",
    "            'Binary Data': [],\n",
    "            'Email Data': [],\n",
    "            'Temporal Data': [],\n",
    "            'id data': []  # Example for spatial data\n",
    "        }\n",
    "\n",
    "        for col in self.columns:\n",
    "            dtype = self[col].dtype\n",
    "\n",
    "            if pd.api.types.is_integer_dtype(dtype):\n",
    "                unique_values = self[col].nunique()\n",
    "                if unique_values == 2:\n",
    "                    classifications['Binary Data'].append(col)\n",
    "                classifications['Integer Data'].append(col)\n",
    "                classifications['Numeric Data'].append(col)\n",
    "            elif pd.api.types.is_float_dtype(dtype):\n",
    "                classifications['Float Data'].append(col)\n",
    "                classifications['Numeric Data'].append(col)\n",
    "            elif pd.api.types.is_object_dtype(dtype):\n",
    "                if self[col].str.contains('@').all():\n",
    "                    classifications['Email Data'].append(col)\n",
    "                else:\n",
    "                    classifications['Categorical Data'].append(col)\n",
    "            elif pd.api.types.is_datetime64_any_dtype(dtype):\n",
    "                classifications['Temporal Data'].append(col)\n",
    "\n",
    "        self.classifications = classifications\n",
    "\n",
    "    @property\n",
    "    def _constructor(self):\n",
    "        return ClassifiedDataFrame\n",
    "\n",
    "# Read CSV file\n",
    "data = ClassifiedDataFrame(pd.read_csv('/teamspace/studios/this_studio/data/csv-clean/synthetic000-cleaned.csv'))\n",
    "\n",
    "# Classify columns\n",
    "data.classify_columns()\n",
    "\n",
    "# Save classifications to a file\n",
    "import json\n",
    "with open('/teamspace/studios/this_studio/csvandmetadata export /json/classifications_0000.json', 'w') as f:\n",
    "    json.dump(data.classifications, f)\n",
    "\n",
    "# Print column classifications\n",
    "for classification, columns in data.classifications.items():\n",
    "    print(f\"{classification}: {columns}\")\n",
    "\n",
    "# Example usage: get all numeric columns\n",
    "numeric_columns = data.classifications['Numeric Data']\n",
    "print(\"Numeric columns:\", numeric_columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integer Data: []\n",
      "Float Data: ['Available Extra Rooms in Hospital', 'Visitors with Patient', 'Admission_Deposit']\n",
      "Numeric Data: ['Available Extra Rooms in Hospital', 'Visitors with Patient', 'Admission_Deposit']\n",
      "Categorical Data: ['Department', 'Ward_Type', 'Bed Grade', 'Type of Admission', 'Severity of Illness', 'Age', 'Stay']\n",
      "Binary Data: []\n",
      "Email Data: []\n",
      "Temporal Data: []\n",
      "Spatial Data: []\n",
      "ID Data: ['case_id', 'Hospital_code', 'Hospital_type_code', 'City_Code_Hospital', 'Hospital_region_code', 'Ward_Facility_Code', 'patientid', 'City_Code_Patient']\n",
      "\n",
      "Numeric columns: ['Available Extra Rooms in Hospital', 'Visitors with Patient', 'Admission_Deposit']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "class ClassifiedDataFrame(pd.DataFrame):\n",
    "    _metadata = ['classifications']\n",
    "\n",
    "    def classify_columns(self):\n",
    "        classifications = {\n",
    "            'Integer Data': [],\n",
    "            'Float Data': [],\n",
    "            'Numeric Data': [],\n",
    "            'Categorical Data': [],\n",
    "            'Binary Data': [],\n",
    "            'Email Data': [],\n",
    "            'Temporal Data': [],\n",
    "            'Spatial Data': [],  # Example for spatial data\n",
    "            'ID Data': []  # Example for ID data\n",
    "        }\n",
    "\n",
    "        for col in self.columns:\n",
    "            dtype = self[col].dtype\n",
    "\n",
    "            # Check for ID columns based on common patterns\n",
    "            if any(substring in col.lower() for substring in ['id', 'num', 'code']):\n",
    "                classifications['ID Data'].append(col)\n",
    "                continue  # Skip further classification if identified as ID\n",
    "\n",
    "            if pd.api.types.is_integer_dtype(dtype):\n",
    "                unique_values = self[col].nunique()\n",
    "                if unique_values == 2:\n",
    "                    classifications['Binary Data'].append(col)\n",
    "                classifications['Integer Data'].append(col)\n",
    "                classifications['Numeric Data'].append(col)\n",
    "            elif pd.api.types.is_float_dtype(dtype):\n",
    "                classifications['Float Data'].append(col)\n",
    "                classifications['Numeric Data'].append(col)\n",
    "            elif pd.api.types.is_object_dtype(dtype):\n",
    "                if self[col].str.contains('@').all():\n",
    "                    classifications['Email Data'].append(col)\n",
    "                else:\n",
    "                    classifications['Categorical Data'].append(col)\n",
    "            elif pd.api.types.is_datetime64_any_dtype(dtype):\n",
    "                classifications['Temporal Data'].append(col)\n",
    "            elif dtype.name == 'geometry':\n",
    "                classifications['Spatial Data'].append(col)\n",
    "\n",
    "        self.classifications = classifications\n",
    "\n",
    "    @property\n",
    "    def _constructor(self):\n",
    "        return ClassifiedDataFrame\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Read CSV file into ClassifiedDataFrame\n",
    "    data = ClassifiedDataFrame(pd.read_csv('sample-synthetic-healthcare.csv'))\n",
    "\n",
    "    # Classify columns\n",
    "    data.classify_columns()\n",
    "\n",
    "    # Save classifications to a JSON file\n",
    "    import json\n",
    "    with open('/teamspace/studios/this_studio/csvandmetadata export /json/classifications.json', 'w') as f:\n",
    "        json.dump(data.classifications, f, indent=4)\n",
    "\n",
    "    # Print column classifications\n",
    "    for classification, columns in data.classifications.items():\n",
    "        print(f\"{classification}: {columns}\")\n",
    "\n",
    "    # Example usage: get all numeric columns\n",
    "    numeric_columns = data.classifications['Numeric Data']\n",
    "    print(\"\\nNumeric columns:\", numeric_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/teamspace/studios/this_studio/csvandmetadata export /json/classifications.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Load classifications from a file\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/teamspace/studios/this_studio/csvandmetadata export /json/classifications.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      6\u001b[0m     classifications \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Create a new DataFrame with the classifications\u001b[39;00m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/IPython/core/interactiveshell.py:308\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    303\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    304\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m     )\n\u001b[0;32m--> 308\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/teamspace/studios/this_studio/csvandmetadata export /json/classifications.json'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Load classifications from a file\n",
    "with open('/teamspace/studios/this_studio/csvandmetadata export /json/classifications.json', 'r') as f:\n",
    "    classifications = json.load(f)\n",
    "\n",
    "# Create a new DataFrame with the classifications\n",
    "data = ClassifiedDataFrame(pd.read_csv('/teamspace/studios/this_studio/sample-synthetic-healthcare-cleaned.csv'))\n",
    "data.classifications = classifications\n",
    "\n",
    "# Print column classifications\n",
    "for classification, columns in data.classifications.items():\n",
    "    print(f\"{classification}: {columns}\")\n",
    "\n",
    "# Example usage: get all numeric columns\n",
    "numeric_columns = data.classifications['Numeric Data']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        8\n",
      "1        2\n",
      "2       10\n",
      "3       26\n",
      "4       26\n",
      "        ..\n",
      "9994    26\n",
      "9995    27\n",
      "9996    28\n",
      "9997    29\n",
      "9998    11\n",
      "Name: Hospital_code, Length: 9999, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data[numeric_columns[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integer Data: []\n",
      "Float Data: ['Available Extra Rooms in Hospital', 'Visitors with Patient', 'Admission_Deposit']\n",
      "Numeric Data: ['Available Extra Rooms in Hospital', 'Visitors with Patient', 'Admission_Deposit']\n",
      "Categorical Data: ['Department', 'Ward_Type', 'Bed Grade', 'Type of Admission', 'Severity of Illness', 'Age', 'Stay']\n",
      "Binary Data: []\n",
      "Email Data: []\n",
      "Temporal Data: []\n",
      "Spatial Data: []\n",
      "ID Data: ['case_id', 'Hospital_code', 'Hospital_type_code', 'City_Code_Hospital', 'Hospital_region_code', 'Ward_Facility_Code', 'patientid', 'City_Code_Patient']\n",
      "\n",
      "Numeric columns: ['Available Extra Rooms in Hospital', 'Visitors with Patient', 'Admission_Deposit']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "\n",
    "class ClassifiedDataFrame(pd.DataFrame):\n",
    "    _metadata = ['classifications']\n",
    "\n",
    "    def classify_columns(self):\n",
    "        classifications = {\n",
    "            'Integer Data': [],\n",
    "            'Float Data': [],\n",
    "            'Numeric Data': [],\n",
    "            'Categorical Data': [],\n",
    "            'Binary Data': [],\n",
    "            'Email Data': [],\n",
    "            'Temporal Data': [],\n",
    "            'Spatial Data': [],\n",
    "            'ID Data': []  # Example for ID data\n",
    "        }\n",
    "\n",
    "        for col in self.columns:\n",
    "            dtype = self[col].dtype\n",
    "\n",
    "            if pd.api.types.is_integer_dtype(dtype):\n",
    "                unique_values = self[col].nunique()\n",
    "                if unique_values == 2:\n",
    "                    classifications['Binary Data'].append(col)\n",
    "                classifications['Integer Data'].append(col)\n",
    "                classifications['Numeric Data'].append(col)\n",
    "            elif pd.api.types.is_float_dtype(dtype):\n",
    "                classifications['Float Data'].append(col)\n",
    "                classifications['Numeric Data'].append(col)\n",
    "            elif pd.api.types.is_object_dtype(dtype):\n",
    "                if self[col].str.contains('@').all():\n",
    "                    classifications['Email Data'].append(col)\n",
    "                else:\n",
    "                    classifications['Categorical Data'].append(col)\n",
    "            elif pd.api.types.is_datetime64_any_dtype(dtype):\n",
    "                classifications['Temporal Data'].append(col)\n",
    "            elif dtype.name == 'geometry':\n",
    "                classifications['Spatial Data'].append(col)\n",
    "            elif any(substring in col.lower() for substring in ['id', 'num', 'code']):\n",
    "                classifications['ID Data'].append(col)\n",
    "\n",
    "        self.classifications = classifications\n",
    "\n",
    "    @property\n",
    "    def _constructor(self):\n",
    "        return ClassifiedDataFrame\n",
    "\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Define the path to your cleaned CSV file and classifications JSON file\n",
    "    csv_file_path = '/teamspace/studios/this_studio/sample-synthetic-healthcare-cleaned.csv'\n",
    "    classifications_file_path = '/teamspace/studios/this_studio/csvandmetadata export /json/classification.json'\n",
    "\n",
    "    # Load classifications from a file\n",
    "    with open(classifications_file_path, 'r') as f:\n",
    "        classifications = json.load(f)\n",
    "\n",
    "    # Read CSV file into ClassifiedDataFrame\n",
    "    data = ClassifiedDataFrame(pd.read_csv(csv_file_path))\n",
    "\n",
    "    # Set classifications\n",
    "    data.classifications = classifications\n",
    "\n",
    "    # Print column classifications\n",
    "    for classification, columns in data.classifications.items():\n",
    "        print(f\"{classification}: {columns}\")\n",
    "\n",
    "    # Example usage: get all numeric columns\n",
    "    numeric_columns = data.classifications['Numeric Data']\n",
    "    print(\"\\nNumeric columns:\", numeric_columns)\n",
    "\n",
    "    numeric_columns[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "class ClassifiedDataFrame(pd.DataFrame):\n",
    "    _metadata = ['classifications']\n",
    "\n",
    "    def classify_columns(self):\n",
    "        classifications = {\n",
    "            'Integer Data': [],\n",
    "            'Float Data': [],\n",
    "            'Numeric Data': [],\n",
    "            'Categorical Data': [],\n",
    "            'Binary Data': [],\n",
    "            'Email Data': [],\n",
    "            'Temporal Data': [],\n",
    "            'Spatial Data': [],\n",
    "            'ID Data': []  # Example for ID data\n",
    "        }\n",
    "\n",
    "        for col in self.columns:\n",
    "            dtype = self[col].dtype\n",
    "\n",
    "            if pd.api.types.is_integer_dtype(dtype):\n",
    "                unique_values = self[col].nunique()\n",
    "                if unique_values == 2:\n",
    "                    classifications['Binary Data'].append(col)\n",
    "                classifications['Integer Data'].append(col)\n",
    "                classifications['Numeric Data'].append(col)\n",
    "            elif pd.api.types.is_float_dtype(dtype):\n",
    "                classifications['Float Data'].append(col)\n",
    "                classifications['Numeric Data'].append(col)\n",
    "            elif pd.api.types.is_object_dtype(dtype):\n",
    "                if self[col].str.contains('@').all():\n",
    "                    classifications['Email Data'].append(col)\n",
    "                else:\n",
    "                    classifications['Categorical Data'].append(col)\n",
    "            elif pd.api.types.is_datetime64_any_dtype(dtype):\n",
    "                classifications['Temporal Data'].append(col)\n",
    "            elif dtype.name == 'geometry':\n",
    "                classifications['Spatial Data'].append(col)\n",
    "            elif any(substring in col.lower() for substring in ['id', 'num', 'code']):\n",
    "                classifications['ID Data'].append(col)\n",
    "\n",
    "        self.classifications = classifications\n",
    "#not using below code\n",
    "    @property\n",
    "    def _constructor(self):\n",
    "        return ClassifiedDataFrame\n",
    "\n",
    "    def get_numeric_data(self):\n",
    "        data_copy = self.copy()  # Make a copy of the current instance\n",
    "        numeric_columns = data_copy.classifications['Numeric Data']\n",
    "        return data_copy[numeric_columns]\n",
    "\n",
    "    def get_integer_data(self):\n",
    "        data_copy = self.copy()  # Make a copy of the current instance\n",
    "        integer_columns = data_copy.classifications['Integer Data']\n",
    "        return data_copy[integer_columns]\n",
    "\n",
    "    def get_float_data(self):\n",
    "        data_copy = self.copy()  # Make a copy of the current instance\n",
    "        float_columns = data_copy.classifications['Float Data']\n",
    "        return data_copy[float_columns]\n",
    "\n",
    "    def get_categorical_data(self):\n",
    "        data_copy = self.copy()  # Make a copy of the current instance\n",
    "        categorical_columns = data_copy.classifications['Categorical Data']\n",
    "        return data_copy[categorical_columns]\n",
    "\n",
    "    def get_email_data(self):\n",
    "        data_copy = self.copy()  # Make a copy of the current instance\n",
    "        email_columns = data_copy.classifications['Email Data']\n",
    "        return data_copy[email_columns]\n",
    "\n",
    "    def get_temporal_data(self):\n",
    "        data_copy = self.copy()  # Make a copy of the current instance\n",
    "        temporal_columns = data_copy.classifications['Temporal Data']\n",
    "        return data_copy[temporal_columns]\n",
    "\n",
    "    def get_spatial_data(self):\n",
    "        data_copy = self.copy()  # Make a copy of the current instance\n",
    "        spatial_columns = data_copy.classifications['Spatial Data']\n",
    "        return data_copy[spatial_columns]\n",
    "\n",
    "    def get_id_data(self):\n",
    "        data_copy = self.copy()  # Make a copy of the current instance\n",
    "        id_columns = data_copy.classifications['ID Data']\n",
    "        return data_copy[id_columns]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    csv_file_path = '/teamspace/studios/this_studio/sample-synthetic-healthcare.csv'\n",
    "    classifications_file_path = '/teamspace/studios/this_studio/csvandmetadata export /json/classification.json'\n",
    "\n",
    "    # Load classifications from a file\n",
    "    with open(classifications_file_path, 'r') as f:\n",
    "        classifications = json.load(f)\n",
    "\n",
    "    # Read CSV file into ClassifiedDataFrame\n",
    "    data = ClassifiedDataFrame(pd.read_csv(csv_file_path))\n",
    "\n",
    "    # Assign classifications to the original data\n",
    "    data.classifications = classifications\n",
    "\n",
    "    # Perform operations on copies and combine results\n",
    "    numeric_data = data.get_numeric_data()\n",
    "    integer_data = data.get_integer_data()\n",
    "    float_data = data.get_float_data()\n",
    "    categorical_data = data.get_categorical_data()\n",
    "    email_data = data.get_email_data()\n",
    "    temporal_data = data.get_temporal_data()\n",
    "    spatial_data = data.get_spatial_data()\n",
    "    id_data = data.get_id_data()\n",
    "\n",
    "    # Combine results into a single DataFrame for export\n",
    "    combined_data = pd.concat([numeric_data, integer_data, float_data, categorical_data,\n",
    "                               email_data, temporal_data, spatial_data, id_data], axis=1)\n",
    "\n",
    "    # Export combined_data to CSV or other formats\n",
    "    combined_data.to_csv('/teamspace/studios/this_studio/combined_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "class ClassifiedDataFrame(pd.DataFrame):\n",
    "    _metadata = ['classifications']  # Custom metadata to be preserved during copy\n",
    "\n",
    "    @property\n",
    "    def _constructor(self):\n",
    "        return ClassifiedDataFrame\n",
    "\n",
    "\n",
    "    def get_numeric_data(self):\n",
    "        data_copy = self.copy()\n",
    "        numeric_columns = data_copy.classifications['Numeric Data']\n",
    "        return data_copy[numeric_columns]\n",
    "\n",
    "    def get_integer_data(self):\n",
    "        data_copy = self.copy()\n",
    "        integer_columns = data_copy.classifications['Integer Data']\n",
    "        return data_copy[integer_columns]\n",
    "\n",
    "    def get_float_data(self):\n",
    "        data_copy = self.copy()\n",
    "        float_columns = data_copy.classifications['Float Data']\n",
    "        return data_copy[float_columns]\n",
    "\n",
    "    def get_categorical_data(self):\n",
    "        data_copy = self.copy()\n",
    "        categorical_columns = data_copy.classifications['Categorical Data']\n",
    "        return data_copy[categorical_columns]\n",
    "\n",
    "    def get_email_data(self):\n",
    "        data_copy = self.copy()\n",
    "        email_columns = data_copy.classifications['Email Data']\n",
    "        return data_copy[email_columns]\n",
    "\n",
    "    def get_temporal_data(self):\n",
    "        data_copy = self.copy()\n",
    "        temporal_columns = data_copy.classifications['Temporal Data']\n",
    "        return data_copy[temporal_columns]\n",
    "\n",
    "    def get_spatial_data(self):\n",
    "        data_copy = self.copy()\n",
    "        spatial_columns = data_copy.classifications['Spatial Data']\n",
    "        return data_copy[spatial_columns]\n",
    "\n",
    "    def get_id_data(self):\n",
    "        data_copy = self.copy()\n",
    "        id_columns = data_copy.classifications['ID Data']\n",
    "        return data_copy[id_columns]\n",
    "\n",
    "    def copy(self, deep=True):\n",
    "        data_copy = super().copy(deep=deep)\n",
    "        data_copy.classifications = self.classifications\n",
    "        return data_copy\n",
    "\n",
    "# Example usage\n",
    "csv_file_path = '/teamspace/studios/this_studio/sample-synthetic-healthcare.csv'\n",
    "classifications_file_path = '/teamspace/studios/this_studio/csvandmetadata export /json/classification.json'\n",
    "\n",
    "# Load classifications from a file\n",
    "with open(classifications_file_path, 'r') as f:\n",
    "    classifications = json.load(f)\n",
    "\n",
    "# Read CSV file into ClassifiedDataFrame\n",
    "data = ClassifiedDataFrame(pd.read_csv(csv_file_path))\n",
    "\n",
    "# Assign classifications to the original data\n",
    "data.classifications = classifications\n",
    "\n",
    "# Perform operations on copies and combine results\n",
    "numeric_data = data.get_numeric_data()\n",
    "integer_data = data.get_integer_data()\n",
    "float_data = data.get_float_data()\n",
    "categorical_data = data.get_categorical_data()\n",
    "email_data = data.get_email_data()\n",
    "temporal_data = data.get_temporal_data()\n",
    "spatial_data = data.get_spatial_data()\n",
    "id_data = data.get_id_data()\n",
    "\n",
    "# Combine results into a single DataFrame for export\n",
    "combined_data = pd.concat([numeric_data, integer_data, float_data, categorical_data,\n",
    "                           email_data, temporal_data, spatial_data, id_data], axis=1)\n",
    "\n",
    "# Export combined_data to CSV or other formats\n",
    "combined_data.to_csv('/teamspace/studios/this_studio/combined_data2.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Available Extra Rooms in Hospital  Visitors with Patient  \\\n",
      "count                        9998.000000            9998.000000   \n",
      "mean                            3.098620               3.325165   \n",
      "std                             1.145543               1.874151   \n",
      "min                             1.000000               1.000000   \n",
      "25%                             2.000000               2.000000   \n",
      "50%                             3.000000               3.000000   \n",
      "75%                             4.000000               4.000000   \n",
      "max                            10.000000              24.000000   \n",
      "\n",
      "       Admission_Deposit  Available Extra Rooms in Hospital.1  \\\n",
      "count        9999.000000                          9998.000000   \n",
      "mean         4956.923892                             3.098620   \n",
      "std          1050.421324                             1.145543   \n",
      "min          1979.000000                             1.000000   \n",
      "25%          4278.000000                             2.000000   \n",
      "50%          4834.000000                             3.000000   \n",
      "75%          5470.000000                             4.000000   \n",
      "max         10314.000000                            10.000000   \n",
      "\n",
      "       Visitors with Patient.1  Admission_Deposit.1      case_id  \\\n",
      "count              9998.000000          9999.000000  9999.000000   \n",
      "mean                  3.325165          4956.923892  5000.000000   \n",
      "std                   1.874151          1050.421324  2886.607005   \n",
      "min                   1.000000          1979.000000     1.000000   \n",
      "25%                   2.000000          4278.000000  2500.500000   \n",
      "50%                   3.000000          4834.000000  5000.000000   \n",
      "75%                   4.000000          5470.000000  7499.500000   \n",
      "max                  24.000000         10314.000000  9999.000000   \n",
      "\n",
      "       Hospital_code  City_Code_Hospital      patientid  City_Code_Patient  \n",
      "count    9999.000000         9998.000000    9999.000000        9889.000000  \n",
      "mean       18.874487            4.726845   66672.836684           6.922742  \n",
      "std         8.683699            3.215743   37535.762586           4.294279  \n",
      "min         1.000000            1.000000     170.000000           1.000000  \n",
      "25%        11.000000            2.000000   35281.500000           4.000000  \n",
      "50%        21.000000            5.000000   67657.000000           8.000000  \n",
      "75%        26.000000            7.000000   98863.000000           8.000000  \n",
      "max        32.000000           13.000000  131507.000000          34.000000  \n"
     ]
    }
   ],
   "source": [
    "kf= pd.read_csv('combined_data2.csv')\n",
    "kv = pd.DataFrame(kf)\n",
    "ad = kv.describe()\n",
    "print(ad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "opration on data \n",
    "1. inspect data as i know in each column\n",
    "like opration if data is binay do one hot encoder\n",
    "if there less than or equal to  4 types of categarial uniiqe values in column do one hot encoding \n",
    "2. discribe data \n",
    "  3 opration has to do \n",
    "  1. if data spetial like contiouns date or value continus for regression\n",
    "  2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if  data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized DataFrame:\n",
      "   Numeric_Column1  Numeric_Column2\n",
      "0        -1.414214        -1.414214\n",
      "1        -0.707107        -0.707107\n",
      "2         0.000000         0.000000\n",
      "3         0.707107         0.707107\n",
      "4         1.414214         1.414214\n",
      "\n",
      "Normalized DataFrame:\n",
      "   Numeric_Column1  Numeric_Column2\n",
      "0             0.00             0.00\n",
      "1             0.25             0.25\n",
      "2             0.50             0.50\n",
      "3             0.75             0.75\n",
      "4             1.00             1.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Example DataFrame (replace this with your actual DataFrame kf)\n",
    "data = {\n",
    "    'Numeric_Column1': [1, 2, 3, 4, 5],\n",
    "    'Numeric_Column2': [10, 20, 30, 40, 50],\n",
    "    'Categorical_Column': ['A', 'B', 'A', 'C', 'B']\n",
    "}\n",
    "kf = pd.DataFrame(data)\n",
    "\n",
    "# Select numeric columns for scaling\n",
    "numeric_columns = kf.select_dtypes(include='number')\n",
    "\n",
    "# Standardization\n",
    "scaler = StandardScaler()\n",
    "kf_standardized = scaler.fit_transform(numeric_columns)\n",
    "kf_standardized = pd.DataFrame(kf_standardized, columns=numeric_columns.columns)\n",
    "\n",
    "# Normalization\n",
    "scaler = MinMaxScaler()\n",
    "kf_normalized = scaler.fit_transform(numeric_columns)\n",
    "kf_normalized = pd.DataFrame(kf_normalized, columns=numeric_columns.columns)\n",
    "\n",
    "print(\"Standardized DataFrame:\")\n",
    "print(kf_standardized)\n",
    "print(\"\\nNormalized DataFrame:\")\n",
    "print(kf_normalized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling function numeric columns\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "def choose_scaling_method_numeric(data):\n",
    "    \"\"\"\n",
    "    Determine whether to apply standardization or normalization based on data characteristics.\n",
    "    \n",
    "    Parameters:\n",
    "    data (DataFrame): Input DataFrame with numeric columns.\n",
    "    \n",
    "    Returns:\n",
    "    str: 'standardize' or 'normalize' based on the chosen method.\n",
    "    \"\"\"\n",
    "    numeric_columns = data.select_dtypes(include='number')\n",
    "    min_max_range = numeric_columns.max() - numeric_columns.min()\n",
    "    \n",
    "    if min_max_range.mean() < 10:\n",
    "        return 'normalize'  # Use normalization if range is small (indicating bounded data)\n",
    "    elif numeric_columns.abs().skew().mean() > 0.5:\n",
    "        return 'standardize'  # Use standardization if data is skewed\n",
    "    else:\n",
    "        return 'standardize'  # Default to standardization\n",
    "\n",
    "scaling_method = choose_scaling_method_numeric(data)\n",
    "print(\"Chosen scaling method:\", scaling_method)\n",
    "    \n",
    "# Replace this with your actual DataFrame kf\n",
    "data = pd.read_csv('combined_data2.csv')\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "# Perform chosen scaling method\n",
    "if scaling_method == 'standardize':\n",
    "    scaler = StandardScaler()\n",
    "    scaled_data = scaler.fit_transform(data.select_dtypes(include='number'))\n",
    "    scaled_data = pd.DataFrame(scaled_data, columns=data.select_dtypes(include='number').columns)\n",
    "elif scaling_method == 'normalize':\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_data = scaler.fit_transform(data.select_dtypes(include='number'))\n",
    "    scaled_data = pd.DataFrame(scaled_data, columns=data.select_dtypes(include='number').columns)\n",
    "else:\n",
    "    raise ValueError(\"Unknown scaling method chosen.\")\n",
    "\n",
    "print(\"Scaled Data:\")\n",
    "print(scaled_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'if' statement on line 34 (1782996350.py, line 35)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[3], line 35\u001b[0;36m\u001b[0m\n\u001b[0;31m    elif classification == 'categorical data':\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'if' statement on line 34\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# Load data from CSV file (replace with your actual CSV file path)\n",
    "data = pd.read_csv('combined_data2.csv')\n",
    "\n",
    "# Load classifications from JSON file (replace with your actual JSON file path)\n",
    "classifications_file_path = '/teamspace/studios/this_studio/csvandmetadata export /json/classification.json'\n",
    "with open(classifications_file_path, 'r') as f:\n",
    "    classifications = json.load(f)\n",
    "\n",
    "numeric_columns = data.select_dtypes(include='number')\n",
    "min_max_range = numeric_columns.max() - numeric_columns.min()\n",
    "\n",
    "\n",
    "# Define a function to apply operations based on classifications\n",
    "def apply_operations_based_on_classification(data, classifications):\n",
    "    # Convert classifications to lowercase keys for easier matching\n",
    "    classifications_lower = {k.lower(): v for k, v in classifications.items()}\n",
    "    \n",
    "    # Initialize scalers for numeric data\n",
    "    scaler_standard = StandardScaler()\n",
    "    scaler_minmax = MinMaxScaler()\n",
    "\n",
    "    # Process each column in the DataFrame\n",
    "    for col in data.columns:\n",
    "        # Check if the column has a classification\n",
    "        col_lower = col.lower()  # Convert column name to lowercase for matching\n",
    "        if col_lower in classifications_lower:\n",
    "            classification = classifications_lower[col_lower]\n",
    "            if classification == 'numeric data':\n",
    "                # Apply standardization\n",
    "                #data[col] = scaler_standard.fit_transform(data[[col]])\n",
    "            if min_max_range.mean() < 10:\n",
    "               return 'normalize'  # Use normalization if range is small (indicating bounded data)\n",
    "            elif numeric_columns.abs().skew().mean() > 0.5:\n",
    "               return 'standardize'  # Use standardization if data is skewed\n",
    "            else:\n",
    "                return 'standardize'  # Default to standardization\n",
    "            #if classification == 'numeric data':\n",
    "            elif classification == 'categorical data':\n",
    "                # Perform operations for categorical data (if needed)\n",
    "                pass\n",
    "            elif classification == 'temporal data':\n",
    "                # Perform operations for temporal data (if needed)\n",
    "                pass\n",
    "            # Add more conditions for other classifications as needed\n",
    "\n",
    "    return data\n",
    "\n",
    "# Apply operations based on classifications\n",
    "data_processed = apply_operations_based_on_classification(data, classifications)\n",
    "\n",
    "# Example: Print first few rows of processed data\n",
    "print(data_processed.head())\n",
    "\n",
    "# Example: Save the processed data back to CSV\n",
    "data_processed.to_csv('processed_combined_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   case_id  Hospital_code Hospital_type_code  City_Code_Hospital  \\\n",
      "0        1              8                  c             3.00000   \n",
      "1        2              2                  c             5.00000   \n",
      "2        3             10                  e             1.00000   \n",
      "3        4             26                  b             4.69814   \n",
      "4        5             26                  b             2.00000   \n",
      "\n",
      "  Hospital_region_code  Available Extra Rooms in Hospital    Department  \\\n",
      "0                    Z                                3.0  radiotherapy   \n",
      "1                    Z                                2.0  radiotherapy   \n",
      "2                    X                                2.0    anesthesia   \n",
      "3                    Y                                2.0  radiotherapy   \n",
      "4                    Y                                2.0  radiotherapy   \n",
      "\n",
      "  Ward_Type Ward_Facility_Code Bed Grade  patientid  City_Code_Patient  \\\n",
      "0         R                  F       2.0      31397                7.0   \n",
      "1         S                  F       2.0      31397                7.0   \n",
      "2         S                  E       2.0      31397                7.0   \n",
      "3         R                  D       2.0      31397                7.0   \n",
      "4         S                  D       2.0      31397                7.0   \n",
      "\n",
      "  Type of Admission Severity of Illness  Visitors with Patient    Age  \\\n",
      "0         Emergency             Extreme                    2.0  51-60   \n",
      "1            Trauma             Extreme                    2.0  51-60   \n",
      "2            Trauma             Extreme                    2.0  51-60   \n",
      "3            Trauma             Extreme                    2.0  51-60   \n",
      "4            Trauma             Extreme                    2.0  51-60   \n",
      "\n",
      "   Admission_Deposit   Stay  \n",
      "0             4911.0   0-10  \n",
      "1             5954.0  41-50  \n",
      "2             4745.0  31-40  \n",
      "3             7272.0  41-50  \n",
      "4             5558.0  41-50  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# Load data from CSV file (replace with your actual CSV file path)\n",
    "data = pd.read_csv('/teamspace/studios/this_studio/data/csv-clean/synthetic2-cleaned.csv')\n",
    "\n",
    "# Load classifications from JSON file (replace with your actual JSON file path)\n",
    "classifications_file_path = '/teamspace/studios/this_studio/csvandmetadata export /json/classification.json'\n",
    "with open(classifications_file_path, 'r') as f:\n",
    "    classifications = json.load(f)\n",
    "\n",
    "# Define a function to apply operations based on classifications\n",
    "def apply_operations_based_on_classification(data, classifications):\n",
    "    # Convert classifications to lowercase keys for easier matching\n",
    "    classifications_lower = {k.lower(): v for k, v in classifications.items()}\n",
    "    \n",
    "    # Identify numeric columns\n",
    "    numeric_columns = data.select_dtypes(include='number')\n",
    "    \n",
    "    # Calculate min-max range for numeric columns\n",
    "    min_max_range = numeric_columns.max() - numeric_columns.min()\n",
    "    \n",
    "    # Initialize scalers\n",
    "    scaler_standard = StandardScaler()\n",
    "    scaler_minmax = MinMaxScaler()\n",
    "\n",
    "    # Process each column in the DataFrame\n",
    "    for col in data.columns:\n",
    "        col_lower = col.lower()  # Convert column name to lowercase for matching\n",
    "        \n",
    "        if col_lower in classifications_lower:\n",
    "            classification = classifications_lower[col_lower]\n",
    "            \n",
    "            if classification == 'numeric data':\n",
    "                if min_max_range.mean() < 10:\n",
    "                    # Use MinMaxScaler for normalization if range is small\n",
    "                    data[col] = scaler_minmax.fit_transform(data[[col]])\n",
    "                elif numeric_columns[col].abs().skew() > 0.5:\n",
    "                    # Use StandardScaler for standardization if data is skewed\n",
    "                    data[col] = scaler_standard.fit_transform(data[[col]])\n",
    "                else:\n",
    "                    # Default to StandardScaler if no specific conditions are met\n",
    "                    data[col] = scaler_standard.fit_transform(data[[col]])\n",
    "            \n",
    "            # Add conditions for other classifications if needed\n",
    "            elif classification == 'categorical data':\n",
    "                # Handle categorical data (if needed)\n",
    "                pass\n",
    "            elif classification == 'temporal data':\n",
    "                # Handle temporal data (if needed)\n",
    "                pass\n",
    "\n",
    "    return data\n",
    "\n",
    "# Apply operations based on classifications\n",
    "data_processed = apply_operations_based_on_classification(data, classifications)\n",
    "\n",
    "# Example: Print first few rows of processed data\n",
    "print(data_processed.head())\n",
    "\n",
    "# Example: Save the processed data back to CSV\n",
    "data_processed.to_csv('processed_combined_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric Data: ['case_id', 'Hospital_code', 'City_Code_Hospital', 'Available Extra Rooms in Hospital', 'patientid', 'City_Code_Patient', 'Visitors with Patient', 'Age', 'Admission_Deposit']\n",
      "Categorical Data: ['Hospital_type_code', 'Hospital_region_code', 'Department', 'Ward_Type', 'Ward_Facility_Code', 'Bed Grade', 'Type of Admission', 'Severity of Illness', 'Stay']\n",
      "Binary Data: []\n",
      "Email Data: []\n",
      "Temporal Data: []\n",
      "id data: []\n",
      "Numeric columns: ['case_id', 'Hospital_code', 'City_Code_Hospital', 'Available Extra Rooms in Hospital', 'patientid', 'City_Code_Patient', 'Visitors with Patient', 'Age', 'Admission_Deposit']\n"
     ]
    }
   ],
   "source": [
    "#final classifiacaton\n",
    "import pandas as pd\n",
    "\n",
    "import json\n",
    "\n",
    "class ClassifiedDataFrame(pd.DataFrame):\n",
    "    _metadata = ['classifications']\n",
    "\n",
    "    def classify_columns(self):\n",
    "        classifications = {\n",
    "            'Numeric Data': [],\n",
    "            'Categorical Data': [],\n",
    "            'Binary Data': [],\n",
    "            'Email Data': [],\n",
    "            'Temporal Data': [],\n",
    "            'id data': []  # Example for spatial data\n",
    "        }\n",
    "\n",
    "        for col in self.columns:\n",
    "            dtype = self[col].dtype\n",
    "\n",
    "            if pd.api.types.is_integer_dtype(dtype) or pd.api.types.is_float_dtype(dtype):\n",
    "                unique_values = self[col].nunique()\n",
    "                if pd.api.types.is_integer_dtype(dtype) and unique_values == 2:\n",
    "                    classifications['Binary Data'].append(col)\n",
    "                classifications['Numeric Data'].append(col)\n",
    "            elif pd.api.types.is_object_dtype(dtype):\n",
    "                if self[col].str.contains('@').all():\n",
    "                    classifications['Email Data'].append(col)\n",
    "                else:\n",
    "                    classifications['Categorical Data'].append(col)\n",
    "            elif pd.api.types.is_datetime64_any_dtype(dtype):\n",
    "                classifications['Temporal Data'].append(col)\n",
    "\n",
    "        self.classifications = classifications\n",
    "\n",
    "    @property\n",
    "    def _constructor(self):\n",
    "        return ClassifiedDataFrame\n",
    "\n",
    "# Read CSV file\n",
    "data = ClassifiedDataFrame(pd.read_csv('/teamspace/studios/this_studio/data/csv-clean/synthetic565-cleaned.csv'))\n",
    "\n",
    "# Classify columns\n",
    "data.classify_columns()\n",
    "\n",
    "# Save classifications to a file\n",
    "with open('/teamspace/studios/this_studio/csvandmetadata export /json/claasification_555.json', 'w') as f:\n",
    "    json.dump(data.classifications, f)\n",
    "\n",
    "# Print column classifications\n",
    "for classification, columns in data.classifications.items():\n",
    "    print(f\"{classification}: {columns}\")\n",
    "\n",
    "# Example usage: get all numeric columns\n",
    "numeric_columns = data.classifications['Numeric Data']\n",
    "print(\"Numeric columns:\", numeric_columns)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
